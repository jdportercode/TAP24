{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3e89c5b3",
   "metadata": {},
   "source": [
    "<img align=\"left\" src=\"https://ithaka-labs.s3.amazonaws.com/static-files/images/tdm/tdmdocs/tapi-logo-small.png\" />\n",
    "\n",
    "This notebook free for educational reuse under [Creative Commons CC BY License](https://creativecommons.org/licenses/by/4.0/).\n",
    "\n",
    "Created by J.D. Porter  for the 2024 Text Analysis Pedagogy Institute, with support from [Constellate](https://constellate.org).\n",
    "<br />\n",
    "____"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68f932d1",
   "metadata": {},
   "source": [
    "# `Small Language Models` `2`\n",
    "\n",
    "This is lesson `2` of 3 in the educational series on `small language models`. This notebook is intended `to teach methods for finding key words in context (KWIC), moving from there to counting collocates, and restructuring collocate data as an array`. \n",
    "\n",
    "**Skills:** \n",
    "* Text analysis\n",
    "* Python\n",
    "\n",
    "**Audience:** `Teachers` / `Learners` / `Researchers`\n",
    "\n",
    "**Use case:** `Tutorial`\n",
    "\n",
    "**Difficulty:** `Beginner`\n",
    "\n",
    "**Completion time:** `90 minutes`\n",
    "\n",
    "**Knowledge Required:** \n",
    "```\n",
    "* Python basics (variables, functions, lists, dictionaries)\n",
    "```\n",
    "\n",
    "**Knowledge Recommended:**\n",
    "```\n",
    "n/a\n",
    "```\n",
    "\n",
    "**Learning Objectives:**\n",
    "After this lesson, learners will be able to:\n",
    "```\n",
    "1. Find the context for a target term in a text\n",
    "2. Count the collocates for a target term in a text\n",
    "3. Structure collocate information as an array\n",
    "```\n",
    "**Research Pipeline:**\n",
    "```\n",
    "If you want to try some of this on your own, you can:\n",
    "1. Gather some texts and save them on your machine as .txt files\n",
    "2. Use whatever steps you're interested in from this notebook\n",
    "3. Interpret!\n",
    "```\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "157c0555",
   "metadata": {},
   "source": [
    "# Required Python Libraries\n",
    " * To keep things simple, we will try to work with very few libraries in this notebook (just 'os', which you do not need to install, though you do need to import it)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5480e2a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Import Libraries ###\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dedd148",
   "metadata": {},
   "source": [
    "# Required Data\n",
    "\n",
    "**Data Format:** \n",
    "* plain text (.txt)\n",
    "\n",
    "**Data Source:**\n",
    "* included files (though you may supplement these whenever you feel comfortable doing so!)\n",
    "\n",
    "**Data Quality/Bias:**\n",
    "\n",
    "Included texts are from freely available sources like Project Gutenberg and Wikipedia. They have not been vetted for textual accuracy relative to, say, a scholarly edition.\n",
    "\n",
    "**Data Description:**\n",
    "\n",
    "This lesson uses textual data in .txt format (utf-8 encoding) from various sources."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f53edaa2",
   "metadata": {},
   "source": [
    "# Introduction..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b74ac5e9-6c17-4cb1-9d2c-9292a486f2e8",
   "metadata": {},
   "source": [
    "Here are a few ideas mentioned in Monday's session:\n",
    " * \"we can capture information about the meanings of words by measuring **how they go together in texts**\"\n",
    " * \"if you know **how words are distributed across a big corpus** of language, you can determine their semantic properties (and possibly other components of meaning as well)\"\n",
    " * \"we look up **how often the words** \"penguin\", \"duck\", and \"eagle\" **appear near the word** \"flies\"\"\n",
    "\n",
    "Today we'll get more specific about what it means for words to \"go together\", to \"appear near\" each other, or to be \"distributed across a corpus\". On a philosophical level, these ideas are rich and complex. On a practical level, though, exploring them is surprisingly simple.\n",
    "\n",
    "We'll begin by thinking about Key Words in Context (KWIC), move on to collocates, and then end by rearranging our data into an array (if this term is less intuitive for you, you can basically think of it as a table, and you'll have the idea). The first two steps are useful in their own right; you can do a lot of productive analysis even if you stop at either. The last is really more of preparatory step for Friday. But all three help us see how we can quantify the theoretical ideas expressed above."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eca42822",
   "metadata": {},
   "source": [
    "# KWIC\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03452096-dec6-420f-84e8-2ff95afeb569",
   "metadata": {},
   "source": [
    "Key Words in Context, or KWIC, is a term for finding the words that surround some target term. A list of KWICs is similar to a concordance. The steps for producing KWICs are pretty straightforward:\n",
    "\n",
    "1. Decide on a window size, *n*\n",
    "2. Find every instance of a target term\n",
    "3. Grab all the words *n* to the left and *n* to the right of the target term\n",
    "\n",
    "Let's say our target term is \"truth\", and we have the following passage:\n",
    "\n",
    "\"It is a **truth** universally acknowledged, that a single man in possession of a good fortune must be in want of a wife. However little known the feelings or views of such a man may be on his first entering a neighbourhood, this **truth** is so well fixed in the minds of the surrounding families, that he is considered as the rightful property of some one or other of their daughters.\"\n",
    "\n",
    "If our window size is 3, we get the following KWICS:\n",
    "\n",
    "    it is a truth universally acknowledged that\n",
    "    a neighbourhood this truth is so well\n",
    "\n",
    "Or with a window size of 10, we'd have:\n",
    "\n",
    "    it is a truth universally acknowledged that a single man in possession of a\n",
    "    man may be on his first entering a neighbourhood this truth is so well fixed in the minds of the surrounding\n",
    "\n",
    "Not too complicated! There's a lot to decide (how big should the window be? Should we include the target term? How do we handle beginnings and endings?). But the gist is simple, and the payoff is pretty clear too: This helps us isolate a term and see something about how it's used. So let's dig in!\n",
    "\n",
    "We'll begin by turning a text file into some words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4878ddfd-e201-429d-8bcb-c3d7d194142f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here are some useful functions we built on Monday\n",
    "\n",
    "# Takes a txt filename and returns a list of its words\n",
    "def file2words(somefilename,clean = True):\n",
    "    with open(somefilename) as source:\n",
    "        text = source.read()\n",
    "    words = text.split()\n",
    "    if clean:\n",
    "        words = [cleanword(w) for w in words]\n",
    "    return words\n",
    "\n",
    "# Takes a word and returns a cleaned up version of it\n",
    "# This works a little differently than the version from Monday\n",
    "def cleanword(someword,remove_apostrophe=True):\n",
    "    word = someword.casefold()\n",
    "    while word and not word[0].isalpha():\n",
    "        word = word[1:]\n",
    "    while word and not word[-1].isalpha():\n",
    "        word = word[:-1]\n",
    "    return word\n",
    "\n",
    "# Takes a count dictionary and returns a sorted list of its key,value pairs\n",
    "def sortdict(somecountdict):\n",
    "    s = sorted(somecountdict,key = lambda i:somecountdict[i],reverse=True)\n",
    "    sorted_counts = [(word,somecountdict[word]) for word in s]\n",
    "    return sorted_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "555e5a88-8ed9-4420-876d-26d68ffa853f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We'll work with a small passage for now\n",
    "\n",
    "passage = \"It is a truth universally acknowledged, that a single man in possession of a good fortune must be in want of a wife. However little known the feelings or views of such a man may be on his first entering a neighbourhood, this truth is so well fixed in the minds of the surrounding families, that he is considered as the rightful property of some one or other of their daughters.\"\n",
    "\n",
    "words = passage.split()\n",
    "words = [cleanword(w) for w in words]\n",
    "\n",
    "words[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "866795bb-dd59-424b-b024-ce08e22e2ed8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# You can use 'enumerate' to keep track of where you are as you iterate through something\n",
    "\n",
    "a = 'apple'\n",
    "l = ['ant','bug','cat','dog','elk']\n",
    "\n",
    "for n,letter in enumerate(a):\n",
    "    print(n,letter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68ee85dd-742f-4b26-bded-4281928aab55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's build a KWIC function together\n",
    "# Remember that in Python, lists retain order!\n",
    "\n",
    "# Takes a target term and find its KWICs in some list of words\n",
    "def get_KWIC(sometargetterm,somewords,window = 3,excl_target = True):\n",
    "    KWIC = []\n",
    "    for n,word in enumerate(somewords):\n",
    "        if word == sometargetterm:\n",
    "            start = max(n-window,0)\n",
    "            end = min(n+window+1,len(somewords)-1)\n",
    "            if excl_target:\n",
    "                k = somewords[start:n] + somewords[n+1:end]\n",
    "            else:\n",
    "                k = somewords[start:end]\n",
    "            KWIC.append(k)\n",
    "    return KWIC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c34f480d-1724-4603-8ca9-c7c8b4af2d61",
   "metadata": {},
   "outputs": [],
   "source": [
    "l[1:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b13225d8-6751-4fa8-89f0-2787896583ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "kwics = get_KWIC('is',words,window=5)\n",
    "for k in kwics:\n",
    "    outstr = \" \".join(k)\n",
    "    print(outstr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "179abf0e-1bfd-4c21-be89-9334c65d4aec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seeing KWICs in action in a file\n",
    "\n",
    "fn = 'Fitzgerald_GreatGatsby.txt'\n",
    "\n",
    "words = file2words(fn)\n",
    "\n",
    "kwics = get_KWIC('tom',words,window=10)\n",
    "\n",
    "# for k in kwics:\n",
    "#     outstr = \" \".join(k)\n",
    "    # print(outstr,\"\\n\")\n",
    "\n",
    "# Getting KWICs for multiple terms\n",
    "\n",
    "kwic_d = {}\n",
    "\n",
    "target_terms = ['daisy','tom','gatsby','nick','myrtle']\n",
    "\n",
    "for t in target_terms:\n",
    "    kwic_d[t] = get_KWIC(t,words,window=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad882447-3798-497f-b46d-90e7dc0cc0f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seeing KWICs in action for a larger corpus\n",
    "\n",
    "source_directory = 'jazz_bios'\n",
    "\n",
    "# Takes a directory and returns a list of files of the specified type\n",
    "def dir2files(somedir,file_type='.txt',path=True):\n",
    "    files = os.listdir(source_directory)\n",
    "    if path:\n",
    "        files = [os.path.join(source_directory,f) for f in files]\n",
    "    files = [f for f in files if f.endswith(file_type)]\n",
    "    return files\n",
    "\n",
    "files = dir2files(source_directory,file_type='.txt')\n",
    "\n",
    "kwic_d = {}\n",
    "\n",
    "target_terms = ['trumpet','coronet','guitar','piano','saxophone']\n",
    "\n",
    "for f in files:\n",
    "    words = file2words(f)\n",
    "    for t in target_terms:\n",
    "        if t not in kwic_d:\n",
    "            kwic_d[t] = []\n",
    "        kwics = get_KWIC(t,words,window=5)\n",
    "        for k in kwics:\n",
    "            kwic_d[t].append(k)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e42c9736",
   "metadata": {},
   "source": [
    "# Collocates"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e59a00e5-dcfa-440a-87a6-0ad982a416af",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "The **collocates** of a term are the words that appear near it in some corpus. That is, they're the words that \"co-located\" with the term. Yet another way to put it is that for any target term, its collocates are all of the words in its KWICs. For instance, looking at the KWICs for \"truth\" in our passage with window size 3:\n",
    "\n",
    "    it is a [truth] universally acknowledged that\n",
    "    a neighbourhood this [truth] is so well\n",
    "\n",
    "We'd get the following collocates (leaving out the target term itself):\n",
    "\n",
    "collocate | count\n",
    "----|----\n",
    "it | 1\n",
    "is | 2\n",
    "a | 2\n",
    "universally | 1\n",
    "acknowledged | 1\n",
    "that | 1\n",
    "neighborhood | 1\n",
    "this | 1\n",
    "so | 1\n",
    "well | 1\n",
    "\n",
    "As you can see, what counts as a collocate depends on the window size. We'd get a very different table with a window of 10 or 100 words, and in some applications people even zoom out to the document level. In that case, \"rightful\" would be a collocate of \"uniting\" in *Pride and Prejudice*, even though the former never appears again after the first two sentences, and the latter never appears until the last sentence!\n",
    "\n",
    "Since we already have a way to find KWICs, we'll use it as a step in finding collocates. But it's worth noting that you don't *have* to go through KWICs to get to collocates. You're always collecting collocates from the window surrounding a word, but you don't necessarily need to record all of the relevant contextsâ€”it's fine to skip straight to the counts, if that's all you want."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11c3430a-6422-43a7-807b-c5f7a395d715",
   "metadata": {},
   "outputs": [],
   "source": [
    "kwics = get_KWIC('truth',words,window=3)\n",
    "kwics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "667dce3a-7597-405a-8ef3-d9e6450f5364",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's build a collocate function together, using our existing KWICs function\n",
    "\n",
    "# Take a list of KWICs and return a dictionary of word counts\n",
    "def kwics2colls(somekwiclist):\n",
    "    counts = {}\n",
    "    for k in somekwiclist:\n",
    "        for w in k:\n",
    "            if w not in counts:\n",
    "                counts[w] = 0\n",
    "            counts[w] += 1\n",
    "    return counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd89646f-dc0b-4e14-b716-641866f677e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "colls = kwics2colls(kwics)\n",
    "colls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1ce5911-9182-4db7-a768-c67b42d7f160",
   "metadata": {},
   "outputs": [],
   "source": [
    "# What about the target term itself?\n",
    "sentence = \"Rose is a rose is a rose is a rose.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94bb99e6-8382-4827-8977-361e72ae9f08",
   "metadata": {},
   "outputs": [],
   "source": [
    "stops = file2words('stopwords.txt')\n",
    "stops = [cleanword(w) for w in stops]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00ef7441-7379-4d8d-8573-95b885492044",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Running the collocate procedure on a file\n",
    "\n",
    "fn = 'Fitzgerald_GreatGatsby.txt'\n",
    "\n",
    "words = file2words(fn)\n",
    "\n",
    "target_term = 'series'\n",
    "\n",
    "kwic = get_KWIC(target_term,words,window=10)\n",
    "\n",
    "coll_d = kwics2colls(kwic)\n",
    "\n",
    "s = sortdict(coll_d)\n",
    "s = [i for i in s if i[0] not in stops]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8fd95c0-dde9-47ce-8b75-c17166fb6823",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Working with multiple target_terms\n",
    "\n",
    "fn = 'Fitzgerald_GreatGatsby.txt'\n",
    "\n",
    "words = file2words(fn)\n",
    "\n",
    "target_terms = ['daisy','tom','gatsby','nick','myrtle']\n",
    "\n",
    "all_coll_d = {}\n",
    "\n",
    "for t in target_terms:\n",
    "    kwic = get_KWIC(t,words,window=10)\n",
    "    coll_d = kwics2colls(kwic)\n",
    "    all_coll_d[t] = coll_d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b127ee5-bf0b-4215-896f-c831b6315a40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Looking at some of the results from Gatsby\n",
    "s = sortdict(all_coll_d['nick'])\n",
    "s = [i for i in s if i[0] not in stops]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07089218-6bce-430e-9e2d-eb8a3cfaa4d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the procedure on a corpus in a directory\n",
    "\n",
    "all_coll_d = {}\n",
    "\n",
    "target_terms = ['trumpet','coronet','guitar','piano','saxophone']\n",
    "\n",
    "for f in files:\n",
    "    words = file2words(f)\n",
    "    for t in target_terms:\n",
    "        if t not in all_coll_d:\n",
    "            all_coll_d[t] = {}\n",
    "        kwic = get_KWIC(t,words,window=10)\n",
    "        coll_d = kwics2colls(kwic)\n",
    "        for word,count in coll_d.items():\n",
    "            if word not in all_coll_d[t]:\n",
    "                all_coll_d[t][word] = 0\n",
    "            all_coll_d[t][word] += count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c554504-bb44-45bf-96b4-b89610d1a256",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Looking at some of the results from the jazz corpus\n",
    "s = sortdict(all_coll_d['guitar'])\n",
    "s = [i for i in s if i[0] not in stops]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2368107",
   "metadata": {},
   "source": [
    "# Toward an array"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "561fa663-6413-4659-a822-b33d04f47d48",
   "metadata": {},
   "source": [
    "Let's return for a second to an example from our first session. When we were discussing the distance between various bird words, we modeled their data with a little table:\n",
    "\n",
    "| term | \"flies\" | \"swims\" | \"hockey\" |\n",
    "| ---- | ---- | ---- | ---- |\n",
    "|penguin | 1 | 9 | 9\n",
    "|duck | 8 | 7 | 8\n",
    "|eagle | 10 | 1 | 0\n",
    "\n",
    "This could also be depicted as a series of lists:\n",
    "\n",
    "```Python\n",
    "    penguin = [1,9,9]\n",
    "    duck = [8,7,8]\n",
    "    eagle = [10,1,0]\n",
    "```\n",
    "\n",
    "Now, all we're really showing here is data about a few collocates for each of the bird terms. But we've arranged that data a little differently than in our work in the collocates section, above. The arrangement consists of a series of **vectors**, which, as we learned on Monday, are just lists of numbers. Calculating relationships between words is much easier when we use vectors. We'll get into the details about distance on Friday, but producing the table or vector structure is an important first step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4a89fc2-611a-487a-886f-11b9c47a27a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Before we dig in, an important concept\n",
    "# A list of lists works like a table (and kind of looks like one, too)\n",
    "\n",
    "bird_array = [['term','flies','swims','hockey'],[1,9,9],[8,7,8],[10,1,0]]\n",
    "\n",
    "for row in bird_array:\n",
    "    print(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c35b115-4c59-498c-be96-4d8787cec28f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, let's produce a table that captures the data for every word in our passage\n",
    "\n",
    "words = passage.split()\n",
    "words = [cleanword(w) for w in words]\n",
    "\n",
    "uniques = set(words)\n",
    "\n",
    "all_coll_d = {}\n",
    "\n",
    "for term in uniques:\n",
    "    kwics = get_KWIC(term,words,window=3)\n",
    "    coll_d = kwics2colls(kwics)\n",
    "    all_coll_d[term] = coll_d\n",
    "\n",
    "header = ['term']\n",
    "\n",
    "header.extend(uniques)\n",
    "\n",
    "array = [header]\n",
    "\n",
    "for term,data in all_coll_d.items():\n",
    "    new_row = [term]\n",
    "    for i in header[1:]:\n",
    "        if i in data:\n",
    "            new_row.append(data[i])\n",
    "        else:\n",
    "            new_row.append(0)\n",
    "    array.append(new_row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbc70128-1a2e-4b69-8888-8154ea95240c",
   "metadata": {},
   "outputs": [],
   "source": [
    "for row in array:\n",
    "    print(row[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff4f8e87-4d70-4a17-abb1-664483a76fe2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Next, let's try a table that shows how a few words relate to each other in The Great Gatsby\n",
    "\n",
    "fn = 'Fitzgerald_GreatGatsby.txt'\n",
    "\n",
    "words = file2words(fn)\n",
    "\n",
    "target_terms = ['daisy','tom','gatsby','nick','myrtle']\n",
    "\n",
    "all_coll_d = {}\n",
    "\n",
    "for t in target_terms:\n",
    "    kwic = get_KWIC(t,words,window=10)\n",
    "    coll_d = kwics2colls(kwic)\n",
    "    all_coll_d[t] = coll_d\n",
    "\n",
    "array = [['term']]\n",
    "array[0].extend(target_terms)\n",
    "\n",
    "for person in target_terms:\n",
    "    new_row = [person]\n",
    "    for i in target_terms:\n",
    "        if i in all_coll_d[person]:\n",
    "            new_row.append(all_coll_d[person][i])\n",
    "        else:\n",
    "            new_row.append(0)\n",
    "    array.append(new_row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5611e07e-0ff8-4a03-b92a-e15df04bc296",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_coll_d['daisy']['daisy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7b2dbe7-29df-4891-8b5d-09b96a90c61d",
   "metadata": {},
   "outputs": [],
   "source": [
    "array"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
